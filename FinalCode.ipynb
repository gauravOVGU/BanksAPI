{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "FinalCode.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "pEA0cpGnOPk4",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Berlin government spending data analysis and policy area prediction\n",
        "\n",
        "#BANKSapi GmbH \n",
        "\n",
        "Author: Gaurav Sharma(gaurav.sharma0491juit@gmail.com)\n",
        "\n",
        "**Import packages:**\n",
        "The main packages for doing data analysis, visualizytion and machine learning(prediction) are numpy, pandas, scikit learn, keras, nltk, ibmlearn, pickle, matplotlib and seaborn\n",
        "\n",
        "**classification**\n",
        "\n",
        "Individual expenditures must be allocated based on purpose field, in the appropriate policy area.\n",
        "\n",
        "** Algorithms Evaluated**: SVM, Random Forest, LSTM\n",
        "\n",
        "**Evaluation Results (Accuracy)**: 30% test data\n",
        "\n",
        "**LSTM:** 0.7294230461882691\n",
        "\n",
        "**Random Forest:** 0.6208246763624741\n",
        "\n",
        "**Support Vector Machine:** 0.7012945501038836\n"
      ]
    },
    {
      "metadata": {
        "id": "df2O3WKP7aQJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "c11d2e36-0836-453e-ea20-f8998d534968"
      },
      "cell_type": "code",
      "source": [
        "# Import all necessary packages for data analysis, data preprocessing and supervised machine learning models\n",
        "import re\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import warnings\n",
        "import nltk\n",
        "import seaborn as sn\n",
        "import keras\n",
        "\n",
        "\n",
        "from imblearn.over_sampling import SMOTE\n",
        "\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.linear_model import SGDClassifier\n",
        "\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "from mlxtend.plotting import plot_confusion_matrix\n",
        "\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "\n",
        "from keras.callbacks import EarlyStopping\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.layers import Dense, Embedding, LSTM, SpatialDropout1D\n",
        "from keras.models import Sequential\n",
        "\n",
        "warnings.filterwarnings('ignore')\n",
        "nltk.download('stopwords')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "metadata": {
        "id": "XH8FMhyl7yyu",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Class defination for majority data preprocessing\n",
        "class data_preprocess(object):\n",
        "    \n",
        "    # Class constructor to initialize all necessary resources for data preperation and preprocessing\n",
        "    # Input: data(i.e., input data file)\n",
        "    def __init__(self):\n",
        "      \n",
        "        # Get set of German and English stop words\n",
        "        self.de_stopwords = set(stopwords.words('german'))\n",
        "        self.en_stopwords = set(stopwords.words('english'))\n",
        "        \n",
        "        # Initialize Label Encoder from sklearn.preprocessing package\n",
        "        self.lb_encode = LabelEncoder()\n",
        "        \n",
        "        # Initialize CountVectorizer and TfidfTransformer from sklearn.feature_extraction.text package\n",
        "        self.count_vec = CountVectorizer() \n",
        "        self.tfidf = TfidfTransformer()\n",
        "    \n",
        "    # Function to preprocess data frame object\n",
        "    # Input: data(i.e., input data file)\n",
        "    def train_data(self, data):\n",
        "      \n",
        "        # Select essential data frame columns required for analysis\n",
        "        data = data[['Politikbereich','Zweck','Betrag']]\n",
        "        \n",
        "        # Remove missing or nan values from data frame\n",
        "        data['Zweck'].replace('', np.nan, inplace=True)\n",
        "        data['Politikbereich'].replace('', np.nan, inplace=True)\n",
        "        \n",
        "        # Drop rows with blank values\n",
        "        data.dropna(subset=['Zweck'], inplace=True)\n",
        "        data.dropna(subset=['Politikbereich'], inplace=True)\n",
        "        return data\n",
        "    \n",
        "    \n",
        "    # Function to clean textual data\n",
        "    def clean_text(self, text):\n",
        "        # Process textual data and remove special characters and stopwords\n",
        "        text = BeautifulSoup(text, \"lxml\").text\n",
        "        text = text.lower()\n",
        "        text = re.sub('<br />', '', text)\n",
        "        text = re.sub('(\\n|\\r|\\t)+', ' ', text)\n",
        "        text = re.sub('ß', 'ss', text)\n",
        "        text = re.sub('’', \"'\", text)\n",
        "        text = re.sub('[^a-zA-Z0-9? äöü]+', '', text)\n",
        "        text = re.sub(\"\\d+\", \" \", text)\n",
        "        text = re.sub(' +', ' ', text)\n",
        "        text = text.split()\n",
        "        # Remove stop words, German and English\n",
        "        text = [w for w in text if w not in self.de_stopwords]\n",
        "        text = [w for w in text if w not in self.en_stopwords]\n",
        "        text = [w for w in text if len(w)>1]\n",
        "        text = ' '.join(text)\n",
        "        # Return processed textual data\n",
        "        return text\n",
        "    \n",
        "    # Function to transform catagorical data\n",
        "    # Input: Categorical labels\n",
        "    def label_encoder(self, labels):\n",
        "        trans_labels = self.lb_encode.fit_transform(labels)\n",
        "        return trans_labels\n",
        "    \n",
        "    \n",
        "    # Function to inverse transforme categorical data\n",
        "    # Input: Categorical predictions\n",
        "    def inverse_transform_label(self,y_pred):\n",
        "        y_pred = self.lb_encode.inverse_transform(y_pred)\n",
        "        return y_pred\n",
        "    \n",
        "    # Function to access encoded labels(i.e., target class values)\n",
        "    def return_class_name(self):\n",
        "        labels = self.lb_encode.classes_\n",
        "        return labels\n",
        "      \n",
        "    # Function to fit Countervector and Tfidf on the training dataset\n",
        "    # Input: train data\n",
        "    def ConterVec_fit_tfidf(self, data):\n",
        "        vect_data = self.count_vec.fit_transform(data)\n",
        "        fit_tfidf = self.tfidf.fit_transform(vect_data)\n",
        "        return fit_tfidf\n",
        "    \n",
        "    # Function to process test data instances using transform method to create feature representation of test data\n",
        "    # Input: train data\n",
        "    def ConterVec_tfidf_transform(self, data):\n",
        "        vect_data = self.count_vec.transform(data)\n",
        "        transform_tfidf = self.tfidf.transform(vect_data)\n",
        "        return transform_tfidf\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "CPlU9q1H8Uub",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Class defination for Random Forest algorithm \n",
        "class random_forest_class(object):\n",
        "  \n",
        "    # Class constructor\n",
        "    def __init__(self):\n",
        "        []\n",
        "\n",
        "    # Function for creating classifier object \n",
        "    def random_model(self):\n",
        "        # Random forest train control parameters\n",
        "        random_forest_classifier = RandomForestClassifier(n_estimators=60, \n",
        "                                                          max_depth=49,\n",
        "                                                          random_state=50,\n",
        "                                                          criterion='entropy')\n",
        "        return random_forest_classifier"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "MBuOxP-p8g6L",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Class defination for Support Vector Machine algorithm\n",
        "class svn_class(object):\n",
        "  \n",
        "    # Class constructor\n",
        "    def __init__(self):\n",
        "        []\n",
        "    \n",
        "    # Function for creating classifier object\n",
        "    def svd_model(self):\n",
        "        # SVM train control parameters\n",
        "        svm_ =SGDClassifier(loss='hinge', \n",
        "                           penalty='l2',\n",
        "                           alpha=1e-3, \n",
        "                           random_state=42, \n",
        "                           max_iter=5, \n",
        "                           tol=None)\n",
        "        return sgd"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "AmuljqNj8sPq",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Class defination for Long Short Term Memory networks algorithm\n",
        "class LSTM_class(object):\n",
        "  \n",
        "    # Class constructor to initialize all necessary resources for LSTM training\n",
        "    # Input: emb_dm(i.e., embedding dimensions)\n",
        "    # Input: n_most_common_words(i.e., number of most common words selected)\n",
        "    # Input: max_len(i.e., maximum length of train data)\n",
        "    def __init__(self,emb_dim,n_most_common_words,max_len):\n",
        "        self.emb_dim = emb_dim\n",
        "        self.n_most_common_words = n_most_common_words\n",
        "        self.max_len = max_len\n",
        "    \n",
        "    # Function to rocess catagorical labels(i.e., Target class) for training\n",
        "    # Input: text_data(i.e., training data)\n",
        "    def label(self, text_data):\n",
        "        target_labels = pd.get_dummies(text_data['Politikbereich']).values\n",
        "        return target_labels\n",
        "    \n",
        "    # Function to reprocess training data, generating 3D training data for LSTM model training \n",
        "    def feature(self, data):\n",
        "      \n",
        "        # tokenize input training data\n",
        "        tokenizer = Tokenizer(num_words=self.n_most_common_words, \n",
        "                              filters='!\"#$%&()*+,-./:;<=>?@[\\]^_`{|}~', \n",
        "                              lower=True)\n",
        "        tokenizer.fit_on_texts(data['Zweck'].values)\n",
        "        \n",
        "        # convert generated tokens into sequences\n",
        "        sequences = tokenizer.texts_to_sequences(data['Zweck'].values)\n",
        "        word_index = tokenizer.word_index\n",
        "        print('Found %s unique tokens.' % len(word_index))\n",
        "        \n",
        "        # trim the sequence using max_len parameter\n",
        "        output_sequence = pad_sequences(sequences, maxlen=max_len)\n",
        "        \n",
        "        # return output sequence\n",
        "        return output_sequence\n",
        "        \n",
        "    # Function to defing depp learning models structure and initialize model object\n",
        "    def build_classifier(self, train_data):\n",
        "      \n",
        "        # Create sequential model\n",
        "        classifier = Sequential()\n",
        "        \n",
        "        # Define embedding layer using input parameters n_most_common_words, emb_dim and train_data.shape\n",
        "        classifier.add(Embedding(self.n_most_common_words, \n",
        "                                 self.emb_dim, \n",
        "                                 input_length=train_data.shape[1]))\n",
        "        classifier.add(SpatialDropout1D(0.7))\n",
        "        \n",
        "        # define long short memory characteristics with dropout\n",
        "        classifier.add(LSTM(64, dropout=0.2, \n",
        "                            recurrent_dropout=0.2))\n",
        "        \n",
        "        # Add Dense layer with softmax activation function \n",
        "        classifier.add(Dense(28, \n",
        "                             activation='softmax'))\n",
        "        \n",
        "        # Compile classifier object and return it \n",
        "        classifier.compile(optimizer = 'adam', \n",
        "                           loss = 'categorical_crossentropy', \n",
        "                           metrics = ['accuracy'])\n",
        "        \n",
        "        return classifier"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "sj5YECaT85i7",
        "colab_type": "code",
        "outputId": "eb981bfe-cac2-4672-9eed-fa71bface88c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 7302
        }
      },
      "cell_type": "code",
      "source": [
        "# Class defination of data analysis object, wrapper class for all above classes\n",
        "class analysis_class(object):\n",
        "  \n",
        "    # Class constructor to initialize all necessary resources for data analysis\n",
        "    # Input: data(i.e., Training data)\n",
        "    # Input: emb_dm(i.e., embedding dimensions)\n",
        "    # Input: n_most_common_words(i.e., number of most common words selected)\n",
        "    # Input: max_len(i.e., maximum length of train data)\n",
        "    def __init__(self, data, emb_dim, n_most_common_words, max_len):\n",
        "        self.data = data\n",
        "        self.data_preprocess = data_preprocess(data)\n",
        "        # Initialize machine learning model object\n",
        "        self.svn_object = svn_class()\n",
        "        self.random_forest_object = random_forest_class()\n",
        "        self.lstm_object = LSTM_class(emb_dim, n_most_common_words, max_len)\n",
        "        \n",
        "    # Wrapper functions:\n",
        "    # Function to remove unecessary column and generate training corpus\n",
        "    # Input: data(i.e., Training data)\n",
        "    def call_remove_missing_column(self,data):\n",
        "        corpus = self.data_preprocess.train_data(data)\n",
        "        return corpus\n",
        "    \n",
        "    # Function to call data_preprocess.clean_text method\n",
        "    # Input: text(i.e., Training textual data)\n",
        "    def call_clean_text(self, text):\n",
        "        cleaned_text = self.data_preprocess.clean_text(text)\n",
        "        # return cleaned data\n",
        "        return cleaned_text\n",
        "    \n",
        "    # Function to call data_preprocess.label_encoder function\n",
        "    # Input: labels(i.e., categorical target class attribute)\n",
        "    def call_label_encoder(self,label):\n",
        "        labels = self.data_preprocess.label_encoder(label)\n",
        "        return labels\n",
        "      \n",
        "    # Function to call data_preprocess.return_class_name function\n",
        "    def call_return_class_name(self):\n",
        "        labels = self.data_preprocess.return_class_name()\n",
        "        return labels\n",
        "    \n",
        "    # Function to convert labels into LSTM compatible by calling lstm_object.label function\n",
        "    def call_label(self,label):\n",
        "        labels = self.lstm_object.label(label)\n",
        "        return labels\n",
        "    # Function to call data_preprocess.ConterVec_fit_tfidf function    \n",
        "    def call_ConterVec_fit_tfidf(self,feature):\n",
        "        feature_set = self.data_preprocess.ConterVec_fit_tfidf(feature)\n",
        "        return feature_set\n",
        "     \n",
        "    # Function to call data_preprocess.ConterVec_fit_tfidf function\n",
        "    def call_ConterVec_tfidf_transform(self,feature):\n",
        "        transform_feature = self.data_preprocess.ConterVec_tfidf_transform(feature)\n",
        "        return transform_feature\n",
        "    \n",
        "    # Function to call lstm_object.feature function and generate LSTM training features\n",
        "    def lstm_feature(self, arg_text):\n",
        "        feature_set = self.lstm_object.feature(arg_text)\n",
        "        return feature_set\n",
        "    \n",
        "    # Function to call lstm_object.build_classifier function and initialize LSTM classifier object\n",
        "    def call_lsmt_build_classifier(self, X):\n",
        "        classifier = self.lstm_object.build_classifier(X)\n",
        "        return classifier\n",
        "    \n",
        "    # Function to call svn_object.svd_model function and initialize svm classifier object\n",
        "    def call_svm(self):\n",
        "        svm = self.svn_object.svd_model()\n",
        "        return svm\n",
        "    \n",
        "    # Function to call random_forest_object.random_model function and initialize random forest classifier object\n",
        "    def call_random_forest(self):\n",
        "        random_forest = self.random_forest_object.random_model()\n",
        "        return random_forest\n",
        "        \n",
        "        \n",
        "        \n",
        "if __name__ == '__main__':\n",
        "     \n",
        "    # Load training data from csv file into pandas data frame\n",
        "    with open('tempData.csv', encoding = 'unicode_escape') as f:\n",
        "        data = pd.read_csv(f)\n",
        "    \n",
        "    # Define application parameters\n",
        "    # Number of epochs for LSTM model training\n",
        "    epochs = 50\n",
        "    emb_dim = 128\n",
        "    batch_size = 256\n",
        "    n_most_common_words = 24914\n",
        "    max_len = 130\n",
        "    # train-test split ratio\n",
        "    arg_split_ratio = 0.3\n",
        "    # Enable or disable smote algorithm(i.e., data sampling algorithm) \n",
        "    enamble_smote=True\n",
        "    \n",
        "    # Create analysis_class object\n",
        "    analysis_object = analysis_class(data, emb_dim, n_most_common_words, max_len)\n",
        "    \n",
        "    # Data divided into a training set and prediction set\n",
        "    text_data = analysis_object.call_remove_missing_column(data)\n",
        "    text_data['Zweck'] = text_data['Zweck'].apply(analysis_object.call_clean_text)\n",
        "    text_data['Zweck'].replace('', np.nan, inplace=True)\n",
        "    text_data.dropna(subset=['Zweck'], inplace=True)\n",
        "\n",
        "    # Plot class distribution in training set\n",
        "    plt.figure(3,figsize =(40,40))\n",
        "    fig = plt.figure(figsize=(8,6))\n",
        "    plt.ylabel('Counts', fontsize=13)\n",
        "    text_data.groupby('Politikbereich').Betrag.count().plot.bar(ylim=0)\n",
        "    plt.show()\n",
        "\n",
        "    # Process Politikbereich attribute and remove occurences(i.e., less than 6 instances)  \n",
        "    bytag = text_data.groupby('Politikbereich').aggregate(np.count_nonzero)\n",
        "    tags = bytag[bytag.Zweck >= 6].index\n",
        "    text_data = text_data[text_data['Politikbereich'].isin(tags)]\n",
        "    \n",
        "    \n",
        "    # Convert Politikbereich attribute into target attribute\n",
        "    labels = list(text_data['Politikbereich'])\n",
        "    y = analysis_object.call_label_encoder(labels)\n",
        "        \n",
        "    # Split train and test data using user defined split ratio\n",
        "\n",
        "    X_train, X_test, y_train, y_test = train_test_split(text_data['Zweck'], y, \n",
        "                                                    test_size = arg_split_ratio, \n",
        "                                                    random_state = 10,\n",
        "                                                    stratify=y)\n",
        "    \n",
        "    # Convert textual data into tf-idf values for test and train data\n",
        "    X_train = analysis_object.call_ConterVec_fit_tfidf(X_train)\n",
        "    X_test = analysis_object.call_ConterVec_tfidf_transform(X_test)\n",
        "    \n",
        "    '''Data sampling algorithm is applied only on train data to balance the \n",
        "    classes and to avoid the information leakage problem'''\n",
        "    if enamble_smote:\n",
        "      # Applying smote algorithm to oversample minority classes in train data\n",
        "      smt = SMOTE()\n",
        "      [X_train, y_train] = smt.fit_resample(X_train,y_train)\n",
        "      print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)\n",
        "    \n",
        "    \n",
        "    print('############### SVM result ###############')\n",
        "    \n",
        "    # Model building initialization\n",
        "    sgd_model = analysis_object.call_svm()\n",
        "    \n",
        "    # Train classification model using X_train and y_train\n",
        "    sgd_model.fit(X_train, y_train)\n",
        "    \n",
        "    # Generate predictions on test dataset(i.e., X_test)\n",
        "    svm_y_pred = sgd_model.predict(X_test)\n",
        "    \n",
        "    # Evaluate and print results\n",
        "    print('accuracy %s' % accuracy_score(y_test, svm_y_pred))\n",
        "    print(classification_report(y_test, svm_y_pred))\n",
        "    print(confusion_matrix(y_test, svm_y_pred))\n",
        "    \n",
        "    \n",
        "    print('############### Random Forest result ###############')\n",
        "    \n",
        "    # Model building initialization\n",
        "    random_forest_model = analysis_object.call_random_forest()\n",
        "    \n",
        "    # Train classification model using X_train and y_train\n",
        "    random_forest_model.fit(X_train, y_train)\n",
        "    \n",
        "    # Generate predictions on test dataset(i.e., X_test)\n",
        "    random_y_pred = random_forest_model.predict(X_test)\n",
        "    \n",
        "    # Evaluate and print results\n",
        "    print('accuracy %s' % accuracy_score(y_test,random_y_pred))\n",
        "    print(classification_report(y_test, random_y_pred))\n",
        "    print(confusion_matrix(y_test, random_y_pred))\n",
        "    \n",
        "    print('############## LSTM results ##############')\n",
        "    # Process training data for LSTM model training\n",
        "    # Data preprocessing steps are different for conventional models like Random forest\n",
        "    # LSTM requires input training data in sequential order to capture sentence level information\n",
        "    target_labels = analysis_object.call_label(text_data)\n",
        "    print('Shape of label tensor:', target_labels.shape)\n",
        "    \n",
        "    # Model building initialization, generate sequential textual features\n",
        "    data = analysis_object.lstm_feature(text_data)\n",
        "    \n",
        "    ''' Split train and test data in the ratio of 90:10 '''\n",
        "    train_X, test_X, train_y, test_y = train_test_split(data, target_labels, \n",
        "                                                    test_size = arg_split_ratio, \n",
        "                                                    random_state = 10,\n",
        "                                                    stratify=target_labels)\n",
        "    \n",
        "    # Apply smote algorithm on train data if enamble_smote=True\n",
        "    if enamble_smote:\n",
        "      # Applying smote algorithm to oversample minority classes in train data\n",
        "      smt = SMOTE() \n",
        "      [train_X, train_y] = smt.fit_resample(train_X,train_y)\n",
        "    \n",
        "    # Model building initialization, generate LSTM model\n",
        "    classifier = analysis_object.call_lsmt_build_classifier(train_X)\n",
        "    \n",
        "    # Train classification model using X_train and y_train\n",
        "    classifier.fit(train_X, train_y, batch_size = arg_batch_size, epochs = arg_epochs)\n",
        "    \n",
        "    # Generate predictions on test dataset(i.e., X_test)\n",
        "    y_pred = classifier.predict(test_X)\n",
        "    \n",
        "    # Save trained model for testing script\n",
        "    classifier.save('model.h5')\n",
        "    \n",
        "    # Evaluate and print results\n",
        "    print(accuracy_score(np.argmax(test_y,axis=1),\n",
        "                           np.argmax(y_pred,axis=1)))\n",
        "    print(classification_report(np.argmax(test_y,axis=1),\n",
        "                           np.argmax(y_pred,axis=1)))\n",
        "    print(confusion_matrix(np.argmax(test_y,axis=1),\n",
        "                            np.argmax(y_pred,axis=1)))\n"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 2880x2880 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAf8AAAJZCAYAAACnXDzQAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 576x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "(259840, 20874) (12514, 20874) (259840,) (12514,)\n",
            "############################ SVM result###############\n",
            "accuracy 0.7012945501038836\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.37      0.84      0.51        94\n",
            "           1       0.98      0.72      0.83      3977\n",
            "           2       0.12      0.40      0.19        20\n",
            "           3       0.66      0.66      0.66       398\n",
            "           4       0.04      0.91      0.08        11\n",
            "           5       0.39      0.86      0.54        74\n",
            "           6       0.07      0.76      0.13        17\n",
            "           7       0.12      0.70      0.21        23\n",
            "           8       0.40      0.94      0.57        18\n",
            "           9       0.38      0.90      0.54        94\n",
            "          10       0.69      0.57      0.62       277\n",
            "          11       0.77      0.73      0.75       467\n",
            "          12       0.15      0.51      0.23        71\n",
            "          13       0.53      0.60      0.56       329\n",
            "          14       0.91      0.66      0.77      1154\n",
            "          15       0.17      0.98      0.29        46\n",
            "          16       0.13      0.70      0.22        37\n",
            "          17       0.83      0.46      0.59       845\n",
            "          18       0.05      0.78      0.09        18\n",
            "          19       0.20      0.79      0.32        38\n",
            "          20       0.84      0.48      0.61       841\n",
            "          21       0.97      0.92      0.94      1295\n",
            "          22       0.49      0.47      0.48       330\n",
            "          23       0.35      0.70      0.46       108\n",
            "          24       0.09      0.95      0.16        20\n",
            "          25       0.73      0.94      0.82       293\n",
            "          26       0.80      0.77      0.78      1590\n",
            "          27       0.26      0.55      0.36        29\n",
            "\n",
            "   micro avg       0.70      0.70      0.70     12514\n",
            "   macro avg       0.45      0.72      0.48     12514\n",
            "weighted avg       0.83      0.70      0.74     12514\n",
            "\n",
            "[[  79    0    0    0    2    0    0    0    0    0    0    1    1    1\n",
            "     3    0    0    0    0    1    0    0    0    1    2    0    3    0]\n",
            " [  44 2847   15   60   83   17   20   22    8   34   19   26   53   63\n",
            "    31  108   29   25   92   36   46   23   55   30   33   48   98   12]\n",
            " [   0    0    8    1    0    0    4    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    2    3    0    1    1    0]\n",
            " [   7    4    5  263    2    4    6    9    0    7    2    7    2    7\n",
            "     2    1   10    5    1    6    2    0    8    5   14    2   16    1]\n",
            " [   0    0    0    0   10    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    1    0    0    0    0    0    0    0]\n",
            " [   1    0    1    0    0   64    1    0    0    0    0    2    0    0\n",
            "     0    0    0    0    0    0    0    0    0    4    1    0    0    0]\n",
            " [   0    0    0    1    0    0   13    1    0    1    0    0    0    0\n",
            "     0    0    0    1    0    0    0    0    0    0    0    0    0    0]\n",
            " [   0    0    0    0    1    0    0   16    0    1    0    0    1    0\n",
            "     1    0    0    0    0    0    0    0    0    1    0    1    1    0]\n",
            " [   0    0    0    0    0    0    0    0   17    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    1    0    0    0    0]\n",
            " [   0    0    0    0    0    0    2    0    0   85    0    0    0    0\n",
            "     0    0    0    0    0    1    0    0    0    1    0    0    2    3]\n",
            " [   1    2    1    0    4    0    2    0    0    0  159    2   78    3\n",
            "     0    3    4    0    2    6    1    0    1    0    4    0    4    0]\n",
            " [   3    5    1    3    4    2    1    9    0    4    3  343   18    8\n",
            "     1    9    5    3    9    8    5    0    5    0    4    4   10    0]\n",
            " [   0    0    0    0    0    0    2    1    0    0   19    1   36    4\n",
            "     0    0    0    1    0    2    0    0    1    0    1    1    2    0]\n",
            " [  10    2    1    2   12    1    6    7    1    3    1    2   13  199\n",
            "     7    0    9    6    4    4    0    0   16    4   10    1    8    0]\n",
            " [  19    5    5   19   26    7    8   44    4   18    7   12    7   36\n",
            "   764   15    8   10   16   17   10    5   25   14   13    6   27    7]\n",
            " [   0    0    0    0    0    0    1    0    0    0    0    0    0    0\n",
            "     0   45    0    0    0    0    0    0    0    0    0    0    0    0]\n",
            " [   0    0    0    0    1    4    0    0    0    1    0    0    0    0\n",
            "     0    0   26    0    0    0    0    0    0    1    2    1    1    0]\n",
            " [   8    4    4    7   19   13   53    0    1   14    8    8    7   11\n",
            "    14   20   66  390   14   10    4    3   19   13   32    4   92    7]\n",
            " [   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    1    0    0   14    0    2    0    0    0    1    0    0    0]\n",
            " [   1    0    0    0    0    0    0    0    0    0    0    0    0    1\n",
            "     0    1    2    0    1   30    0    0    0    0    0    0    1    1]\n",
            " [   8    7   10    8   43   10   11    7    6    6    6   32   21   15\n",
            "     2   29   21    4  118    5  407    2   10    6   32    1   13    1]\n",
            " [   1    1    1   17    4   17    7    0    0    8    1    0    3    1\n",
            "     0    6    0    3    4    9    0 1188    3    3    4    2   12    0]\n",
            " [   3    6    5    2   18    7   11   11    5    1    0    2    0    8\n",
            "     9    8    6    9    2    3    2    3  156   26    4    5   15    3]\n",
            " [   0    0    0    0    1    4    1    0    0    0    0    0    2    2\n",
            "     0    0    0    0    0    0    0    0   13   76    5    1    3    0]\n",
            " [   0    0    0    0    0    0    0    0    0    0    0    0    0    1\n",
            "     0    0    0    0    0    0    0    0    0    0   19    0    0    0]\n",
            " [   0    1    0    0    4    2    0    0    0    0    0    1    1    0\n",
            "     0    1    0    0    0    1    0    0    0    1    0  275    6    0]\n",
            " [  27   13    8   14    9   11   32    4    0   33    7    6    5   17\n",
            "     5   21    9   13    5   13    3    2    6   29   33   24 1231   10]\n",
            " [   1    0    0    0    0    1    0    0    0    6    0    1    0    0\n",
            "     0    1    1    0    0    0    0    0    0    0    0    0    2   16]]\n",
            "######################## random forest result ###############\n",
            "accuracy 0.6208246763624741\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.42      0.50      0.46        94\n",
            "           1       0.95      0.63      0.75      3977\n",
            "           2       0.37      0.35      0.36        20\n",
            "           3       0.76      0.60      0.67       398\n",
            "           4       0.00      0.00      0.00        11\n",
            "           5       0.53      0.84      0.65        74\n",
            "           6       0.39      0.71      0.50        17\n",
            "           7       0.19      0.35      0.24        23\n",
            "           8       0.63      0.94      0.76        18\n",
            "           9       0.67      0.88      0.76        94\n",
            "          10       0.77      0.47      0.58       277\n",
            "          11       0.78      0.54      0.64       467\n",
            "          12       0.20      0.41      0.27        71\n",
            "          13       0.51      0.40      0.45       329\n",
            "          14       0.87      0.42      0.57      1154\n",
            "          15       0.74      0.91      0.82        46\n",
            "          16       0.42      0.38      0.40        37\n",
            "          17       0.56      0.32      0.41       845\n",
            "          18       0.09      0.17      0.12        18\n",
            "          19       0.45      0.61      0.52        38\n",
            "          20       0.77      0.48      0.59       841\n",
            "          21       1.00      0.88      0.94      1295\n",
            "          22       0.62      0.43      0.51       330\n",
            "          23       0.32      0.48      0.39       108\n",
            "          24       0.18      0.85      0.30        20\n",
            "          25       0.72      0.75      0.74       293\n",
            "          26       0.32      0.90      0.47      1590\n",
            "          27       0.70      0.48      0.57        29\n",
            "\n",
            "   micro avg       0.62      0.62      0.62     12514\n",
            "   macro avg       0.53      0.56      0.52     12514\n",
            "weighted avg       0.76      0.62      0.65     12514\n",
            "\n",
            "[[  47    1    0    2    0    0    0    0    0    0    0    0    0    4\n",
            "     2    0    0    1    0    0    2    0    1    3    0    0   31    0]\n",
            " [  26 2492    1   35   16    9    0    4    4    6    4   20   38   39\n",
            "    14    8    2   29    2   14   47    0   30   11   12   37 1077    0]\n",
            " [   0    0    7    0    0    0    4    0    0    0    0    0    0    0\n",
            "     1    0    0    1    0    0    0    0    2    3    0    1    1    0]\n",
            " [   6    5    1  240    1    1    1    4    0    5    0    1    0    3\n",
            "     8    0    3   19    0    0    1    0    0    7   10    0   82    0]\n",
            " [   0    0    0    0    0    0    0    0    0    0    0    0    0    1\n",
            "     0    0    0    1    0    0    8    0    0    0    0    0    1    0]\n",
            " [   0    1    1    0    0   62    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    4    0    0    6    0]\n",
            " [   0    1    0    0    0    0   12    0    0    0    0    0    0    0\n",
            "     0    0    0    1    0    0    0    0    0    1    0    0    2    0]\n",
            " [   0    1    0    0    0    0    0    8    0    1    0    0    0    1\n",
            "     0    0    0    0    0    0    0    0    1    2    0    0    9    0]\n",
            " [   0    0    0    0    0    0    0    0   17    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    1    0]\n",
            " [   0    0    0    0    0    0    0    0    0   83    0    0    0    2\n",
            "     0    0    0    1    0    1    0    0    0    0    0    0    7    0]\n",
            " [   2    5    1    1    0    0    0    0    0    0  130    2   34    2\n",
            "     1    0    0    3    0    1    4    0    1    0    4    0   86    0]\n",
            " [   4   20    0    2    0    1    0    4    0    2    1  254   13    5\n",
            "     4    2    0   12    0    3    4    0    0    4    6    4  122    0]\n",
            " [   0    1    0    0    0    0    0    0    0    0   19    1   29    2\n",
            "     1    0    0    2    0    0    0    0    0    0    0    0   16    0]\n",
            " [   5   10    0    1    1    1    0    0    2    2    5    8    7  132\n",
            "     6    0    0   11    0    0    5    0    7    3    8    0  115    0]\n",
            " [   7   26    0   13    6    5    0   20    1    2    0   12    0   20\n",
            "   484    0    0   20    0    2    9    1    7   13    4    9  491    2]\n",
            " [   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     1   42    0    1    0    0    0    0    0    0    0    0    2    0]\n",
            " [   0    0    0    0    0    3    0    0    0    1    0    0    0    0\n",
            "     2    0   14    1    0    0    0    0    0    1    2    1   12    0]\n",
            " [   4   17    3    8    2    4    3    0    0    8    0    5    3   10\n",
            "     5    3   11  273    0    1    6    0   12   14   13    4  435    1]\n",
            " [   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    3    0   13    0    0    0    1    0    1    0]\n",
            " [   2    0    0    0    0    0    0    0    0    0    1    0    0    0\n",
            "     0    0    0    1    0   23    0    0    0    0    0    0   11    0]\n",
            " [   4   17    1    3    4   10    1    0    2    3    1   17   10   13\n",
            "     4    0    1   25   28    1  401    2    5    9    6    2  268    3]\n",
            " [   0    1    0    3    0   10    1    0    0    2    2    0    3    1\n",
            "     9    0    1    9    0    0    5 1146    1    1    1    2   97    0]\n",
            " [   1   13    3    3    1    4    0    2    1    0    3    2    0   13\n",
            "     6    1    1   12    0    3    5    0  142   21    3    5   85    0]\n",
            " [   0    2    0    0    0    1    0    0    0    0    0    0    2    0\n",
            "     1    0    0    4    0    0    0    1   15   52    1    1   28    0]\n",
            " [   0    0    0    0    0    0    0    0    0    0    0    0    0    1\n",
            "     0    0    0    1    0    0    1    0    0    0   17    0    0    0]\n",
            " [   0    0    0    1    4    1    0    0    0    0    0    1    1    0\n",
            "     0    0    0    1    0    0    4    0    0    1    0  220   59    0]\n",
            " [   3    9    1    3    1    3    9    1    0    4    3    2    5    8\n",
            "     7    1    0   57    0    2    4    0    6   11    7   18 1425    0]\n",
            " [   1    3    0    1    0    1    0    0    0    4    0    0    0    0\n",
            "     0    0    0    1    0    0    0    0    0    0    0    0    4   14]]\n",
            "######################## LSTM results##############\n",
            "Shape of label tensor: (41713, 28)\n",
            "Found 24914 unique tokens.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "Epoch 1/50\n",
            "259840/259840 [==============================] - 127s 488us/step - loss: 2.6435 - acc: 0.2793\n",
            "Epoch 2/50\n",
            "259840/259840 [==============================] - 125s 480us/step - loss: 2.1396 - acc: 0.4211\n",
            "Epoch 3/50\n",
            "259840/259840 [==============================] - 126s 484us/step - loss: 1.9601 - acc: 0.4663\n",
            "Epoch 4/50\n",
            "259840/259840 [==============================] - 126s 485us/step - loss: 1.8403 - acc: 0.4955\n",
            "Epoch 5/50\n",
            "259840/259840 [==============================] - 126s 486us/step - loss: 1.7528 - acc: 0.5179\n",
            "Epoch 6/50\n",
            "259840/259840 [==============================] - 124s 476us/step - loss: 1.6815 - acc: 0.5365\n",
            "Epoch 7/50\n",
            "259840/259840 [==============================] - 125s 483us/step - loss: 1.6207 - acc: 0.5521\n",
            "Epoch 8/50\n",
            "259840/259840 [==============================] - 125s 480us/step - loss: 1.5735 - acc: 0.5638\n",
            "Epoch 9/50\n",
            "259840/259840 [==============================] - 123s 475us/step - loss: 1.5315 - acc: 0.5741\n",
            "Epoch 10/50\n",
            "259840/259840 [==============================] - 128s 491us/step - loss: 1.4958 - acc: 0.5830\n",
            "Epoch 11/50\n",
            "259840/259840 [==============================] - 125s 483us/step - loss: 1.4634 - acc: 0.5919\n",
            "Epoch 12/50\n",
            "259840/259840 [==============================] - 126s 485us/step - loss: 1.4390 - acc: 0.5981\n",
            "Epoch 13/50\n",
            "259840/259840 [==============================] - 128s 491us/step - loss: 1.4104 - acc: 0.6056\n",
            "Epoch 14/50\n",
            "259840/259840 [==============================] - 130s 501us/step - loss: 1.3875 - acc: 0.6111\n",
            "Epoch 15/50\n",
            "259840/259840 [==============================] - 124s 478us/step - loss: 1.3686 - acc: 0.6161\n",
            "Epoch 16/50\n",
            "259840/259840 [==============================] - 126s 486us/step - loss: 1.3489 - acc: 0.6213\n",
            "Epoch 17/50\n",
            "259840/259840 [==============================] - 123s 474us/step - loss: 1.3304 - acc: 0.6252\n",
            "Epoch 18/50\n",
            "259840/259840 [==============================] - 126s 483us/step - loss: 1.3159 - acc: 0.6299\n",
            "Epoch 19/50\n",
            "259840/259840 [==============================] - 127s 489us/step - loss: 1.3006 - acc: 0.6323\n",
            "Epoch 20/50\n",
            "259840/259840 [==============================] - 124s 478us/step - loss: 1.2854 - acc: 0.6365\n",
            "Epoch 21/50\n",
            "259840/259840 [==============================] - 123s 475us/step - loss: 1.2729 - acc: 0.6393\n",
            "Epoch 22/50\n",
            "259840/259840 [==============================] - 128s 492us/step - loss: 1.2619 - acc: 0.6420\n",
            "Epoch 23/50\n",
            "259840/259840 [==============================] - 126s 484us/step - loss: 1.2486 - acc: 0.6454\n",
            "Epoch 24/50\n",
            "259840/259840 [==============================] - 125s 479us/step - loss: 1.2395 - acc: 0.6474\n",
            "Epoch 25/50\n",
            "259840/259840 [==============================] - 129s 497us/step - loss: 1.2292 - acc: 0.6501\n",
            "Epoch 26/50\n",
            "259840/259840 [==============================] - 126s 484us/step - loss: 1.2175 - acc: 0.6534\n",
            "Epoch 27/50\n",
            "259840/259840 [==============================] - 128s 493us/step - loss: 1.2117 - acc: 0.6555\n",
            "Epoch 28/50\n",
            "259840/259840 [==============================] - 129s 498us/step - loss: 1.1990 - acc: 0.6590\n",
            "Epoch 29/50\n",
            "259840/259840 [==============================] - 127s 489us/step - loss: 1.1931 - acc: 0.6598\n",
            "Epoch 30/50\n",
            "259840/259840 [==============================] - 127s 490us/step - loss: 1.1852 - acc: 0.6617\n",
            "Epoch 31/50\n",
            "259840/259840 [==============================] - 130s 500us/step - loss: 1.1756 - acc: 0.6644\n",
            "Epoch 32/50\n",
            "259840/259840 [==============================] - 128s 494us/step - loss: 1.1706 - acc: 0.6648\n",
            "Epoch 33/50\n",
            "259840/259840 [==============================] - 127s 487us/step - loss: 1.1650 - acc: 0.6671\n",
            "Epoch 34/50\n",
            "259840/259840 [==============================] - 130s 501us/step - loss: 1.1551 - acc: 0.6690\n",
            "Epoch 35/50\n",
            "259840/259840 [==============================] - 128s 493us/step - loss: 1.1511 - acc: 0.6703\n",
            "Epoch 36/50\n",
            "259840/259840 [==============================] - 127s 489us/step - loss: 1.1425 - acc: 0.6726\n",
            "Epoch 37/50\n",
            "259840/259840 [==============================] - 129s 495us/step - loss: 1.1360 - acc: 0.6740\n",
            "Epoch 38/50\n",
            "259840/259840 [==============================] - 129s 495us/step - loss: 1.1328 - acc: 0.6746\n",
            "Epoch 39/50\n",
            "259840/259840 [==============================] - 126s 485us/step - loss: 1.1242 - acc: 0.6763\n",
            "Epoch 40/50\n",
            "259840/259840 [==============================] - 130s 501us/step - loss: 1.1192 - acc: 0.6783\n",
            "Epoch 41/50\n",
            "259840/259840 [==============================] - 129s 495us/step - loss: 1.1131 - acc: 0.6803\n",
            "Epoch 42/50\n",
            "259840/259840 [==============================] - 127s 490us/step - loss: 1.1095 - acc: 0.6808\n",
            "Epoch 43/50\n",
            "259840/259840 [==============================] - 127s 490us/step - loss: 1.1012 - acc: 0.6818\n",
            "Epoch 44/50\n",
            "259840/259840 [==============================] - 131s 503us/step - loss: 1.0977 - acc: 0.6836\n",
            "Epoch 45/50\n",
            "259840/259840 [==============================] - 127s 489us/step - loss: 1.0938 - acc: 0.6850\n",
            "Epoch 46/50\n",
            "259840/259840 [==============================] - 128s 491us/step - loss: 1.0883 - acc: 0.6872\n",
            "Epoch 47/50\n",
            "259840/259840 [==============================] - 127s 489us/step - loss: 1.0819 - acc: 0.6873\n",
            "Epoch 48/50\n",
            "259840/259840 [==============================] - 128s 492us/step - loss: 1.0786 - acc: 0.6884\n",
            "Epoch 49/50\n",
            "259840/259840 [==============================] - 129s 498us/step - loss: 1.0738 - acc: 0.6902\n",
            "Epoch 50/50\n",
            "259840/259840 [==============================] - 128s 494us/step - loss: 1.0735 - acc: 0.6895\n",
            "0.7294230461882691\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.27      0.67      0.39        94\n",
            "           1       0.99      0.80      0.89      3977\n",
            "           2       0.11      0.55      0.19        20\n",
            "           3       0.72      0.66      0.69       398\n",
            "           4       0.05      0.45      0.08        11\n",
            "           5       0.18      0.66      0.28        74\n",
            "           6       0.06      0.65      0.11        17\n",
            "           7       0.08      0.61      0.14        23\n",
            "           8       0.62      0.83      0.71        18\n",
            "           9       0.59      0.84      0.70        94\n",
            "          10       0.51      0.61      0.55       277\n",
            "          11       0.78      0.73      0.76       467\n",
            "          12       0.15      0.39      0.22        71\n",
            "          13       0.48      0.55      0.51       329\n",
            "          14       0.90      0.73      0.81      1154\n",
            "          15       0.42      0.70      0.52        46\n",
            "          16       0.08      0.51      0.14        37\n",
            "          17       0.70      0.56      0.62       845\n",
            "          18       0.05      0.39      0.09        18\n",
            "          19       0.14      0.71      0.24        38\n",
            "          20       0.83      0.72      0.77       841\n",
            "          21       0.98      0.89      0.94      1295\n",
            "          22       0.43      0.50      0.46       330\n",
            "          23       0.32      0.53      0.40       108\n",
            "          24       0.23      0.70      0.34        20\n",
            "          25       0.91      0.93      0.92       293\n",
            "          26       0.92      0.64      0.75      1590\n",
            "          27       0.08      0.48      0.14        29\n",
            "\n",
            "   micro avg       0.73      0.73      0.73     12514\n",
            "   macro avg       0.45      0.64      0.48     12514\n",
            "weighted avg       0.84      0.73      0.77     12514\n",
            "\n",
            "[[  63    0    0    1    0    1    1    2    0    0    3    2    0    2\n",
            "     2    0    1    0    1    4    2    0    2    1    0    0    5    1]\n",
            " [  38 3196   24   24   36   26   49   49    2    7   41   15   46   58\n",
            "    22    4   56   34   32   48   35    6   42   21   10    6   14   36]\n",
            " [   1    0   11    0    0    1    1    0    0    0    0    0    0    0\n",
            "     2    0    0    1    0    0    0    0    1    2    0    0    0    0]\n",
            " [  10    5    7  264    0    7    7    0    0    0    3    9    4    6\n",
            "    10    6    3   17    2    5    4    0    2    8    5    3    5    6]\n",
            " [   0    0    0    0    5    0    0    0    0    0    0    0    1    0\n",
            "     0    1    0    0    0    0    3    0    0    0    0    0    1    0]\n",
            " [   0    0    0    1    0   49    3    0    0    0    1    1    0    0\n",
            "     1    1    1    4    2    0    1    0    5    2    0    1    1    0]\n",
            " [   0    0    0    0    0    0   11    0    0    0    0    0    0    0\n",
            "     1    0    1    1    1    0    0    0    0    0    0    1    1    0]\n",
            " [   1    0    0    0    0    1    2   14    0    0    1    0    0    0\n",
            "     1    0    0    0    0    1    0    0    0    1    0    1    0    0]\n",
            " [   0    0    0    0    0    2    0    0   15    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    1    0    0    0    0    0    0]\n",
            " [   3    0    3    0    0    0    0    0    0   79    0    1    0    0\n",
            "     1    0    0    2    0    0    0    0    2    0    0    0    3    0]\n",
            " [   3    1    2    3    2    1    6    2    0    0  169    5   28    4\n",
            "     3    1   11    8    9    2    2    0    6    2    0    0    4    3]\n",
            " [   5    2    8    2    5    7    1    1    0    1   12  343    2    5\n",
            "     2    2    5    8    9   12   10    1   10    6    3    0    0    5]\n",
            " [   0    1    0    0    1    1    0    0    0    0   29    0   28    2\n",
            "     0    1    2    2    2    0    0    0    1    0    0    0    1    0]\n",
            " [  17    9    5    4    8    5    5    6    0    5    5    4   11  180\n",
            "     3    0    6    6    7    6    8    0   10    6    3    2    2    6]\n",
            " [  19    7    9    8   12   22   19   33    1    3   11   11   13   22\n",
            "   843    3    8   25   11    7    8    2   25    9    3    3    8    9]\n",
            " [   0    0    0    0    0    0    0    1    0    0    0    0    0    6\n",
            "     2   32    2    0    2    0    0    0    0    0    0    1    0    0]\n",
            " [   1    0    0    0    0    2    1    0    0    1    0    1    0    0\n",
            "     0    0   19    2    0    2    2    0    2    0    1    0    2    1]\n",
            " [  12    4    3   16    2   38   20   18    0    6   16   10    9   10\n",
            "    12    4   36  473    4   19   15    2   33   16    6    3   26   32]\n",
            " [   0    0    0    0    0    0    0    0    0    0    0    0    0    1\n",
            "     0    0    0    0    7    0   10    0    0    0    0    0    0    0]\n",
            " [   1    0    2    0    0    0    3    0    0    0    0    0    0    3\n",
            "     1    0    0    0    0   27    0    0    0    0    1    0    0    0]\n",
            " [  10    1    2   10   16   10    7   17    1    2    9   11   11   17\n",
            "     1    7   13   17   29   10  609    0   12    5    4    1    5    4]\n",
            " [   8    0    1    6    1   16   10    4    2    4    7    9    3    6\n",
            "     3    1    9   12    2    8    1 1155   13    4    1    1    4    4]\n",
            " [   8    5    7    3    2   11    3    5    0    4    6    3    4   18\n",
            "     9    2   11   13    8    6   11    1  165   15    0    0    6    4]\n",
            " [   2    2    2    6    1    1    0    3    0    1    0    4    0    4\n",
            "     0    0    0    2    2    0    1    0   16   57    0    0    2    2]\n",
            " [   0    0    0    0    0    1    1    0    0    0    0    0    0    0\n",
            "     0    0    1    1    0    1    0    0    0    1   14    0    0    0]\n",
            " [   0    0    2    0    0    1    1    3    0    0    1    0    0    1\n",
            "     4    0    2    1    0    0    0    1    1    0    1  272    1    1]\n",
            " [  29    6   10   19   17   66   29   15    3   16   18   11   21   31\n",
            "     9   12   50   50    9   31   10    5   36   21   10    3 1014   39]\n",
            " [   0    1    0    0    0    2    1    1    0    4    1    0    0    0\n",
            "     1    0    0    1    0    0    0    0    1    1    0    0    1   14]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "H5vWburOZ4OP",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "3PB2DsOfa1vS",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}